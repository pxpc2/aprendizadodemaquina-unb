{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "_reconhecedordigitos.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Notebook chapter 04 \n",
        "\n",
        "Autor Pedro Daia Cardoso\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "82jzyHKDon7A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yO-GFYx9xMJt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a12ee91-cbc3-4a79-8a50-07946dd02649"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 719 kB 26.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 64.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 66.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 362 kB 75.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 30.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 101 kB 11.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 212 kB 77.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 140 kB 71.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 62.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 127 kB 77.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 271 kB 73.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 94 kB 4.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 144 kB 67.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 51.2 MB/s \n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[?25hMounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "# Exercício de treinamento, criacao de um modelo reconhecedor dos digitos 3 e 7\n",
        "\n",
        "#hide\n",
        "! [ -e /content ] && pip install -Uqq fastbook\n",
        "import fastbook\n",
        "fastbook.setup_book()\n",
        "from fastbook import *\n",
        "from fastai.vision.widgets import *\n",
        "from fastai.vision.all import *\n",
        "\n",
        "matplotlib.rc('image', cmap='Greys') # para mostrar tudo cinza os vetores"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = untar_data(URLs.MNIST_SAMPLE) # esse sample do reconhecedor universal só tem 3s e 7s\n",
        "Path.BASE_PATH = path\n",
        "threes = (path/'train'/'3').ls().sorted()\n",
        "sevens = (path/'train'/'7').ls().sorted()\n"
      ],
      "metadata": {
        "id": "AkhAVSR-YX94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "d673813c-d7ac-4bd7-e664-bb406f7ff1c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      <progress value='3219456' class='' max='3214948' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.14% [3219456/3214948 00:00<00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos criar um Pytorch tensor para representar a img, é um array do numpy injetavel na GPU\n",
        ">`imgTensor = tensor(Image.open(threes[0]))`"
      ],
      "metadata": {
        "id": "TKVMVo0HzOwe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar listas para guardar todos os setes e os tres\n",
        "sevenTensors = [tensor(Image.open(i)) for i in sevens]\n",
        "threeTensors = [tensor(Image.open(i)) for i in threes]\n",
        "\n",
        "sevenStacked = torch.stack(sevenTensors).float() / 255 # divide por 255 pq imagem tem 255 pixels\n",
        "threeStacked = torch.stack(threeTensors).float() / 255 # mas quando sao img como um float, valores de pixels sao entre 0 e 1\n"
      ],
      "metadata": {
        "id": "zgloJSt0ge2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como nos temos listas, não é util para fazer computacoes matematicas; já um tensor pode ter vários \"eixos/dimensões\", podemos pegar a lista de imgs e \"stackar\" uma em cima da outra criando uma espécie de cubo 3D, com o qual dá pra fazer os calculos\n",
        "\n",
        ">## NOMENCLATURA IMPORTANTE \n",
        ">*   rank = dimensoes de um tensor\n",
        ">*   shape = tamanho de cada dimensao\n",
        "\n",
        "\n",
        "Precisamos medir proximidade de pixels (distância), para comparar os números com a média\n",
        "> L2 Form: pega a MEAN do quadrado das diferencas e dps tira a raiz de tudo\n",
        "\n",
        "\n",
        " "
      ],
      "metadata": {
        "id": "tQlS-xPZzpSo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = threeStacked[0] # vamos ver a distância desse 3 para a média do 3 e pro 7\n",
        "\n",
        "distThree = ((a - threeStacked.mean(0))**2).mean().sqrt()\n",
        "distSeven = ((a - sevenStacked.mean(0))**2).mean().sqrt()\n",
        "\n",
        "if (distThree < distSeven):\n",
        "  print('é um 3')\n",
        "else: \n",
        "  print('é um 7')"
      ],
      "metadata": {
        "id": "HADZ4vK_oxH6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "475d7849-e0d9-4e1d-eab6-679a1623554b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "é um 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Essa já é uma BASELINE válida para o modelo, é bem simples mas é sólida."
      ],
      "metadata": {
        "id": "aJxNyWqsp4fr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pegar a validation set\n",
        "threeValidImg = (path/'valid'/'3').ls().sorted()\n",
        "sevenValidImg = (path/'valid'/'7').ls().sorted()\n",
        "threeValidationTensors = [tensor(Image.open(i)) for i in threeValidImg]\n",
        "sevenValidationTensors = [tensor(Image.open(i)) for i in sevenValidImg]\n",
        "\n",
        "threeStacked_validation = torch.stack(threeValidationTensors).float() / 255\n",
        "sevenStacked_validation = torch.stack(sevenValidationTensors).float() / 255\n",
        "\n",
        "def mnsit_dist(a, b):\n",
        "  return ((a-b)**2).mean((-1,-2)).sqrt()\n",
        "  #eixos -1 e -2 são os horizontal e vertical da img"
      ],
      "metadata": {
        "id": "yoHqQcw6oTEC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`mnsit_dist(three_stackedValidation, stackedThrees.mean(0))` \n",
        "\n",
        "Essa chamada nao reclamaria de diferenca em shape, retornaria o calculo da dist para todos dentro do three_stackedValidation em relacao ao 3 ideal\n",
        ">Nome disso é BROADCASTING, o pytorch altera o rank de um tensor para um cálculo com tensor de rank diferente"
      ],
      "metadata": {
        "id": "zGq3KPWC4ChL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def isThree(a):\n",
        "  return mnsit_dist(a, threeStacked.mean(0)) < mnsit_dist(a, sevenStacked.mean(0))\n",
        "\n",
        "# obs: ao converter bool return pra float, é 1.0 p true e 0.0 p false\n",
        "# vamos calcular a accuracy, a precisão\n",
        "acc_threes = isThree(threeStacked_validation).float().mean()\n",
        "acc_sevens = 1 - (isThree(sevenStacked_validation).float().mean())\n",
        "acc_threes, acc_sevens"
      ],
      "metadata": {
        "id": "LSd7iFJ8u61F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f7046ca-8b00-40eb-c1dc-0fe9c75387fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.9584), tensor(0.9737))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####`(tensor(0.9584), tensor(0.9737))`\n",
        "Este output indica uma precisão de 95% para os 3 e 97% para os 7 bom resultado mas são só 2 numeros, e sao bem diferentes, entao precisa melhorar muito\n",
        "\n",
        "Percebe-se que o sistema ainda não tem uma capacidade de aprendizado, uma forma de alterar parâmetros para melhorar a performance, muito menos como medir algo do tipo.\n",
        "\n",
        ">Ao invés de abordar pela Pixel Similarity, comparando uma img com uma \"imagem ideal\", podemos ter uma abordagem por \"gradiente\"\n",
        ">Com o conceito de pesos, atribuímos pesos maiores a regiões de imagem mais prováveis para certo dígito, como por exemplo em um 7, a região inferior direita teria pesos menores pois é improvável, enquanto em um 8 a mesma região teria pesos maiores.\n",
        "\n",
        "\n",
        "Por exemplo, uma função:\n",
        "```\n",
        "def pr_eight(x,w): return (x*w).sum()\n",
        "```\n",
        "onde *x* é a img, e *w* é um vetor de pesos\n",
        "\n",
        "Ou seja, procurar pela melhor configuração do vetor *w* significa melhorar o reconhecimento do sistema.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tnn3AjRmzId3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Cálculo de um gradiente\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "def f(x): return x**2\n",
        "\n",
        "# requires_grad_()\n",
        "# ^ ^ fc p dizer ao pytorch que quero calc grads nesse ponto c/ rel. a essa var\n",
        "xTensor = tensor(3.).requires_grad_() \n",
        "\n",
        "yt = f(xTensor)\n",
        "yt.backward()\n",
        "xTensor.grad\n",
        "```\n",
        "\n",
        ">output\n",
        "\n",
        ">```\n",
        "tensor(6.)\n",
        "```"
      ],
      "metadata": {
        "id": "A_t1ylZIohEi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos então procurar uma funcao para aplicar o calculo do gradiente, funcao quadrática"
      ],
      "metadata": {
        "id": "JuExhRrn_U9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def f(t, params):\n",
        "  a,b,c = params\n",
        "  return a*(t**2) + b*t + c\n",
        "\n",
        "def mse(preds, targets): return ((preds-targets)**2).mean()"
      ],
      "metadata": {
        "id": "7E7ia8LFpK4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Passos para o processo de Gradient Descent:"
      ],
      "metadata": {
        "id": "tMFZxy_8_clN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "hide_input": true,
        "id": "BqVOz8WK4E5q",
        "outputId": "dff86e70-2bfb-412f-ac72-5e77116bc3cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.files.Source at 0x7f69fdf8bcd0>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: G Pages: 1 -->\n<svg width=\"597pt\" height=\"78pt\"\n viewBox=\"0.00 0.00 596.69 78.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 74)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-74 592.6863,-74 592.6863,4 -4,4\"/>\n<!-- init -->\n<g id=\"node1\" class=\"node\">\n<title>init</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"27\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"27\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">init</text>\n</g>\n<!-- predict -->\n<g id=\"node2\" class=\"node\">\n<title>predict</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"127.3968\" cy=\"-18\" rx=\"36.2938\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"127.3968\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">predict</text>\n</g>\n<!-- init&#45;&gt;predict -->\n<g id=\"edge1\" class=\"edge\">\n<title>init&#45;&gt;predict</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M54.1688,-18C62.3543,-18 71.5827,-18 80.6596,-18\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"80.7795,-21.5001 90.7795,-18 80.7795,-14.5001 80.7795,-21.5001\"/>\n</g>\n<!-- loss -->\n<g id=\"node3\" class=\"node\">\n<title>loss</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"227.7935\" cy=\"-52\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"227.7935\" y=\"-48.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">loss</text>\n</g>\n<!-- predict&#45;&gt;loss -->\n<g id=\"edge2\" class=\"edge\">\n<title>predict&#45;&gt;loss</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M157.5191,-28.2011C168.9806,-32.0826 182.1139,-36.5303 193.9014,-40.5222\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"192.8259,-43.8532 203.4202,-43.7458 195.0713,-37.2231 192.8259,-43.8532\"/>\n</g>\n<!-- gradient -->\n<g id=\"node4\" class=\"node\">\n<title>gradient</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"365.7399\" cy=\"-52\" rx=\"40.8928\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"365.7399\" y=\"-48.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gradient</text>\n</g>\n<!-- loss&#45;&gt;gradient -->\n<g id=\"edge3\" class=\"edge\">\n<title>loss&#45;&gt;gradient</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M255.0473,-52C272.0415,-52 294.4481,-52 314.6545,-52\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"314.671,-55.5001 324.671,-52 314.671,-48.5001 314.671,-55.5001\"/>\n</g>\n<!-- step -->\n<g id=\"node5\" class=\"node\">\n<title>step</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"470.6863\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"470.6863\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">step</text>\n</g>\n<!-- gradient&#45;&gt;step -->\n<g id=\"edge4\" class=\"edge\">\n<title>gradient&#45;&gt;step</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M398.9456,-41.2422C410.9558,-37.3512 424.5297,-32.9536 436.6132,-29.0388\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"437.9112,-32.2975 446.3457,-25.8857 435.7537,-25.6382 437.9112,-32.2975\"/>\n</g>\n<!-- step&#45;&gt;predict -->\n<g id=\"edge6\" class=\"edge\">\n<title>step&#45;&gt;predict</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M443.4266,-18C384.9297,-18 246.7861,-18 174.0495,-18\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"173.8098,-14.5001 163.8098,-18 173.8097,-21.5001 173.8098,-14.5001\"/>\n<text text-anchor=\"middle\" x=\"289.7935\" y=\"-21.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">repeat</text>\n</g>\n<!-- stop -->\n<g id=\"node6\" class=\"node\">\n<title>stop</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"561.6863\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"561.6863\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">stop</text>\n</g>\n<!-- step&#45;&gt;stop -->\n<g id=\"edge5\" class=\"edge\">\n<title>step&#45;&gt;stop</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M497.9893,-18C506.2676,-18 515.508,-18 524.3268,-18\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"524.4026,-21.5001 534.4025,-18 524.4025,-14.5001 524.4026,-21.5001\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "gv('''\n",
        "init->predict->loss->gradient->step->stop\n",
        "step->predict[label=repeat]\n",
        "''')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -1 indica aumentar tamanho do eixo x o qto precisar, e 28*28 no y pois as imgs sao 28x28 px\n",
        "train_x = torch.cat([threeStacked, sevenStacked]).view(-1, 28*28) # rank3 (lista de matrizes) para rank 2 (lista de vetores)\n",
        "train_y = tensor([1]*len(threes) + [0]*len(sevens)).unsqueeze(1) # labels 1 para 3s e 0 para 7s\n",
        "\n",
        "# Criar um DataSet p/ o PyTorch, que tem que ser estrutura que quando buscar um index, retorna uma tuple\n",
        "dset = list(zip(train_x, train_y))\n",
        "#x,y = dset[0]\n",
        "#x.shape, y # x=img(28*28 px), y=label(1=num3)\n",
        "\n",
        "# repetir o mesmo para o validation set\n",
        "validation_x = torch.cat([threeStacked_validation, sevenStacked_validation]).view(-1, 28*28) \n",
        "validation_y = tensor([1]*len(threeStacked_validation) + [0]*len(sevenStacked_validation)).unsqueeze(1)\n",
        "validationDset = list(zip(validation_x , validation_y))"
      ],
      "metadata": {
        "id": "MpvZL09_8X0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora devemos começar o primeiro passo do Gradient Descent\n",
        "\n",
        "> initialize: atribuir, primeiramente de forma aleatória, pesos para cada pixel \n",
        "\n"
      ],
      "metadata": {
        "id": "FNmWG9se-F51"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def init_params(size, std=1.0): return (torch.randn(size)*std).requires_grad_()\n",
        "weights = init_params((28*28,1))\n",
        "# y = w*x + b\n",
        "bias = init_params(1)"
      ],
      "metadata": {
        "id": "2bgOReAm_pe-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> y = w*x + b\n",
        "\n",
        "####Em redes neurais, os pesos (w, weights) e o bias (b) juntos formam os parâmetros de um modelo.  \n",
        "\n",
        "####Agora, calcularemos um chute inicial de parametros para as imagens. Vale a pena lembrar que não queremos utilizar um loop nativo do Python para iterar as imagens pois seria muito lento, então trabalharemos na GPU usando cálculo de multiplicaćão de matrizes para cada linha da matriz."
      ],
      "metadata": {
        "id": "FVPs78ymAsfm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#(train_x[0]*weights.T).sum() + bias # para 1 imagem\n",
        "def matrixProduct(x_batch): return x_batch@weights + bias\n",
        "chutes = matrixProduct(train_x)\n",
        "chutes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysufcA6AB_jP",
        "outputId": "3fefaa18-a507-4606-fc14-7ecaf433340e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ -6.2330],\n",
              "        [-10.6388],\n",
              "        [-20.8865],\n",
              "        ...,\n",
              "        [-15.9176],\n",
              "        [ -1.6866],\n",
              "        [-11.3568]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# checar accuracy\n",
        "corretos = ((chutes > 0.0).float() == train_y).float().mean()\n",
        "corretos"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bICBe1q_FA8s",
        "outputId": "7ad539ff-225d-484a-c657-7dba90fff17c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.5380)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Precisamos de uma fc LOSS para calcular o gradiente.\n",
        "Essa fc tem que ser de uma forma que, quando uma pequena mudanca nos pesos gerar uma pequena mudanca nos chutes, gere um loss um pouco \"melhor\".\n",
        "Neste caso, um loss melhor seria gerado quando a fc retornar um score/confianca maior para um 3 (label y 1, mais prox. de 1), ou um score/confianca menor para um 7 (label y 0, mais prox. de 0)\n",
        "\n",
        "\n",
        "\n",
        "*   Não utilizamos accuracy para cálculo da melhora.\n",
        "\n",
        "ex:\n",
        "\n",
        "\n",
        "```\n",
        "labels          = tensor([1,0,1]) # um 3, um 7 e um 3 é o correto\n",
        "chutes_results  = tensor([0.9, 0.4, 0.2])\n",
        "# 0.9 = alta confianca que era um 3\n",
        "# 0.4 = pouca confianca que era um 7\n",
        "# 0.2 = alta confianca que era um 7, mas incorreto pois era um 3\n",
        "```\n",
        "\n",
        "se, no exemplo acima, chutes_results fosse [1,0,1] o loss seria [0, 0, 0], i.é\n",
        "\n",
        "\n",
        "> quanto mais correto as predicoes/chutes, menor o loss.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9ftGhrcMIXf1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mnist_loss(predictions, targets):\n",
        "  predictions = predictions.sigmoid() ## .sigmoid() p/ garantir estarem todos entre 0 e 1\n",
        "  return torch.where(targets==1, 1-predictions, predictions).mean()"
      ],
      "metadata": {
        "id": "zTSWfHN6KebC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Diferenca chave entre a métrica accuracy, e a fc loss: \n",
        "\n",
        "\n",
        "> metrics são para o entendimento humano, enquanto a fc loss é para o learning da rede neural, o processo automatizado.\n",
        "\n",
        "\n",
        "> Dado isso, é importante saber que deve-se focar na MÉTRICA quando formos julgar a performance de um modelo.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XduGcaTkLdgj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora temos uma fc loss definida, precisamos de fazer o optimization step:  alterar os pesos com base nos gradientes.\n",
        "\n",
        "Iterar todos os items calculando seu loss e as entao mudancas de peso seria muito demorado, então se utiliza um BATCH, i.e, somente um pedaco do total de items por vez para o cálculo, é um comprometimento de precisão porém poupa tempo. Logo, definir o BATCH SIZE é um ponto importante na criacao de modelos, onde um maior pode levar mais tempo para rodar cada epoch, porém gerando resultados melhores e vice-versa.\n",
        "\n",
        "\n",
        "> PyTorch e o fastai providenciam uma classe para nós embaralharmos nossos itens a cada epoch e coletar uma mini-batch, a class *DataLoader*:\n",
        "\n"
      ],
      "metadata": {
        "id": "b3aJ6vgYUyrO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# primeiro criar de ex. um Dataset de tuples (como nossos x_imgs e y_labels)\n",
        "ds = L(enumerate(string.ascii_lowercase))\n",
        "ds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shWuRaF9WWiX",
        "outputId": "c75fe86d-7113-4240-8c70-4ceaff66cca1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#26) [(0, 'a'),(1, 'b'),(2, 'c'),(3, 'd'),(4, 'e'),(5, 'f'),(6, 'g'),(7, 'h'),(8, 'i'),(9, 'j')...]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dl = DataLoader(ds, batch_size=6, shuffle=True) # passamos o DataSet ao DataLoader\n",
        "# isso vai criar então mini batches com todos os itens\n",
        "list(dl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9jgQDpwWp_P",
        "outputId": "a2b6502f-6bfb-4273-cee9-0d8ec84ed5de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(tensor([19, 14,  0, 24, 20, 12]), ('t', 'o', 'a', 'y', 'u', 'm')),\n",
              " (tensor([23,  8,  9,  3, 16,  6]), ('x', 'i', 'j', 'd', 'q', 'g')),\n",
              " (tensor([ 4,  7,  1, 13,  2, 22]), ('e', 'h', 'b', 'n', 'c', 'w')),\n",
              " (tensor([ 5, 17, 18, 10, 11, 15]), ('f', 'r', 's', 'k', 'l', 'p')),\n",
              " (tensor([25, 21]), ('z', 'v'))]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    }
  ]
}