{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "reconhecedordigitos.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Notebook chapter 04 \n",
        "\n",
        "Autor Pedro Daia Cardoso\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "82jzyHKDon7A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yO-GFYx9xMJt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81333e3e-9c02-4ea2-e68a-ed624d734236"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 719 kB 31.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 52.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 362 kB 65.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 61.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 212 kB 63.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 66.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 101 kB 11.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 140 kB 68.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 74.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 127 kB 74.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 271 kB 36.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 144 kB 50.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 94 kB 2.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 63.9 MB/s \n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[?25hMounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "# Exercício de treinamento, criacao de um modelo reconhecedor dos digitos 3 e 7\n",
        "\n",
        "#hide\n",
        "! [ -e /content ] && pip install -Uqq fastbook\n",
        "import fastbook\n",
        "fastbook.setup_book()\n",
        "from fastbook import *\n",
        "from fastai.vision.widgets import *\n",
        "from fastai.vision.all import *\n",
        "\n",
        "matplotlib.rc('image', cmap='Greys') # para mostrar tudo cinza os vetores"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = untar_data(URLs.MNIST_SAMPLE) # esse sample do reconhecedor universal só tem 3s e 7s\n",
        "Path.BASE_PATH = path\n",
        "threes = (path/'train'/'3').ls().sorted()\n",
        "sevens = (path/'train'/'7').ls().sorted()\n"
      ],
      "metadata": {
        "id": "AkhAVSR-YX94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "191e8798-4ea7-453e-c76d-22640f6bbb4f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      <progress value='3219456' class='' max='3214948' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.14% [3219456/3214948 00:01<00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos criar um Pytorch tensor para representar a img, é um array do numpy injetavel na GPU\n",
        ">`imgTensor = tensor(Image.open(threes[0]))`"
      ],
      "metadata": {
        "id": "TKVMVo0HzOwe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar listas para guardar todos os setes e os tres\n",
        "sevenTensors = [tensor(Image.open(i)) for i in sevens]\n",
        "threeTensors = [tensor(Image.open(i)) for i in threes]\n",
        "\n",
        "sevenStacked = torch.stack(sevenTensors).float() / 255 # divide por 255 pq imagem tem 255 pixels\n",
        "threeStacked = torch.stack(threeTensors).float() / 255 # mas quando sao img como um float, valores de pixels sao entre 0 e 1\n"
      ],
      "metadata": {
        "id": "zgloJSt0ge2V"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como nos temos listas, não é util para fazer computacoes matematicas; já um tensor pode ter vários \"eixos/dimensões\", podemos pegar a lista de imgs e \"stackar\" uma em cima da outra criando uma espécie de cubo 3D, com o qual dá pra fazer os calculos\n",
        "\n",
        ">## NOMENCLATURA IMPORTANTE \n",
        ">*   rank = dimensoes de um tensor\n",
        ">*   shape = tamanho de cada dimensao\n",
        "\n",
        "\n",
        "Precisamos medir proximidade de pixels (distância), para comparar os números com a média\n",
        "> L2 Form: pega a MEAN do quadrado das diferencas e dps tira a raiz de tudo\n",
        "\n",
        "\n",
        " "
      ],
      "metadata": {
        "id": "tQlS-xPZzpSo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = threeStacked[0] # vamos ver a distância desse 3 para a média do 3 e pro 7\n",
        "\n",
        "distThree = ((a - threeStacked.mean(0))**2).mean().sqrt()\n",
        "distSeven = ((a - sevenStacked.mean(0))**2).mean().sqrt()\n",
        "\n",
        "if (distThree < distSeven):\n",
        "  print('é um 3')\n",
        "else: \n",
        "  print('é um 7')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HADZ4vK_oxH6",
        "outputId": "1526cf58-4423-41b6-9627-8183867085bb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "é um 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Essa já é uma BASELINE válida para o modelo, é bem simples mas é sólida."
      ],
      "metadata": {
        "id": "aJxNyWqsp4fr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pegar a validation set\n",
        "threeValidImg = (path/'valid'/'3').ls().sorted()\n",
        "sevenValidImg = (path/'valid'/'7').ls().sorted()\n",
        "threeValidationTensors = [tensor(Image.open(i)) for i in threeValidImg]\n",
        "sevenValidationTensors = [tensor(Image.open(i)) for i in sevenValidImg]\n",
        "\n",
        "three_stackedValidation = torch.stack(threeValidationTensors).float() / 255\n",
        "seven_stackedValidation = torch.stack(sevenValidationTensors).float() / 255\n",
        "\n",
        "def mnsit_dist(a, b):\n",
        "  return ((a-b)**2).mean((-1,-2)).sqrt()\n",
        "  #eixos -1 e -2 são os horizontal e vertical da img"
      ],
      "metadata": {
        "id": "yoHqQcw6oTEC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`mnsit_dist(three_stackedValidation, stackedThrees.mean(0))` \n",
        "\n",
        "Essa chamada nao reclamaria de diferenca em shape, retornaria o calculo da dist para todos dentro do three_stackedValidation em relacao ao 3 ideal\n",
        ">Nome disso é BROADCASTING, o pytorch altera o rank de um tensor para um cálculo com tensor de rank diferente"
      ],
      "metadata": {
        "id": "zGq3KPWC4ChL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def isThree(a):\n",
        "  return mnsit_dist(a, threeStacked.mean(0)) < mnsit_dist(a, sevenStacked.mean(0))\n",
        "\n",
        "# obs: ao converter bool return pra float, é 1.0 p true e 0.0 p false\n",
        "# vamos calcular a accuracy, a precisão\n",
        "acc_threes = isThree(three_stackedValidation).float().mean()\n",
        "acc_sevens = 1 - (isThree(seven_stackedValidation).float().mean())\n",
        "acc_threes, acc_sevens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSd7iFJ8u61F",
        "outputId": "976523e4-bd6a-449e-9232-6d9b04a10142"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.9584), tensor(0.9737))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####`(tensor(0.9584), tensor(0.9737))`\n",
        "Este output indica uma precisão de 95% para os 3 e 97% para os 7 bom resultado mas são só 2 numeros, e sao bem diferentes, entao precisa melhorar muito\n",
        "\n",
        "Percebe-se que o sistema ainda não tem uma capacidade de aprendizado, uma forma de alterar parâmetros para melhorar a performance, muito menos como medir algo do tipo.\n",
        "\n",
        ">Ao invés de abordar pela Pixel Similarity, comparando uma img com uma \"imagem ideal\", podemos ter uma abordagem por \"gradiente\"\n",
        ">Com o conceito de pesos, atribuímos pesos maiores a regiões de imagem mais prováveis para certo dígito, como por exemplo em um 7, a região inferior direita teria pesos menores pois é improvável, enquanto em um 8 a mesma região teria pesos maiores.\n",
        "\n",
        "\n",
        "Por exemplo, uma função:\n",
        "```\n",
        "def pr_eight(x,w): return (x*w).sum()\n",
        "```\n",
        "onde *x* é a img, e *w* é um vetor de pesos\n",
        "\n",
        "Ou seja, procurar pela melhor configuração do vetor *w* significa melhorar o reconhecimento do sistema.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tnn3AjRmzId3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Cálculo de um gradiente\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "def f(x): return x**2\n",
        "\n",
        "# requires_grad_()\n",
        "# ^ ^ fc p dizer ao pytorch que quero calc grads nesse ponto c/ rel. a essa var\n",
        "xTensor = tensor(3.).requires_grad_() \n",
        "\n",
        "yt = f(xTensor)\n",
        "yt.backward()\n",
        "xTensor.grad\n",
        "```\n",
        "\n",
        ">output\n",
        "\n",
        ">```\n",
        "tensor(6.)\n",
        "```"
      ],
      "metadata": {
        "id": "A_t1ylZIohEi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def f(t, params):\n",
        "  a,b,c = params\n",
        "  return a*(t**2) + b*t + c\n",
        "\n",
        "def mse(preds, targets): return ((preds-targets)**2).mean()"
      ],
      "metadata": {
        "id": "7E7ia8LFpK4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "MpvZL09_8X0m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}